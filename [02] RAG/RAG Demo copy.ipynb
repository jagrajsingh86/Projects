{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0ccee73",
   "metadata": {},
   "source": [
    "RAG (Retrieval Augmented Generative)\n",
    "\n",
    "Why we create RAG system?\n",
    "Retrieval systems (RAG) give LLM systems access to factual, access-controlled, timely information.\n",
    "\n",
    "1. RAG REDUCES HALLUCINATION\n",
    "Example: In the financial services induftry, providing accurate information on investment options is crucual bcause it directly impacts customers' purchasing decisions and financial well-being.\n",
    "\n",
    "2. COST-EFFECTIVE ALTERNATIVE\n",
    "Example: Banks often need to assess the creditworthiness of potential borrowers. Fine-tuning pre-trained Language models to analyze credit histories can be resource-intensive. RAG architecture.\n",
    "\n",
    "3. CREDIBLE AND ACCURATE RESPONSES\n",
    "Example: In customer support, providing accurate and helpful responses is essential for maintaining customer trust, as it demonstrates the company's commitment to providing reliable information and support.\n",
    "\n",
    "4. DOMAIN-SPEIFIC INFORMATION\n",
    "Example: In the logal industry, clients often require advice specific to their case or jurisdiction becasue different legal systems have unique rules and regulations, and understanding these nuances is crucial for effective legal representation. \n",
    "\n",
    "https://www.advancinganalytics.co.uk/blog/2023/11/7/10-reasons-why-you-need-to-implement-rag-a-game-changer-in-ai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2979131",
   "metadata": {},
   "source": [
    "RAG PRACTICAL USECASES\n",
    "1. Document Question Answering Systems\n",
    "2. Conversational agents\n",
    "3. Real-time event commentary\n",
    "4. Content Generation\n",
    "5. Personalized Recommendation\n",
    "6. Virtual Asisstants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d49777",
   "metadata": {},
   "source": [
    "INSTALLING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09a16464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/2099070/Library/Python/3.13/lib/python/site-packages (1.0.8)\n",
      "Requirement already satisfied: openai in /Users/2099070/Library/Python/3.13/lib/python/site-packages (2.7.1)\n",
      "Requirement already satisfied: tiktoken in /Users/2099070/Library/Python/3.13/lib/python/site-packages (0.12.0)\n",
      "Requirement already satisfied: rapidocr-onnxruntime in /Users/2099070/Library/Python/3.13/lib/python/site-packages (1.2.3)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.0.6 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (0.4.8)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.0.6->langchain) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.6->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.6->langchain) (2.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from tiktoken) (2025.7.34)\n",
      "Requirement already satisfied: pyclipper>=1.2.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (1.3.0.post6)\n",
      "Requirement already satisfied: onnxruntime>=1.7.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (1.22.1)\n",
      "Requirement already satisfied: opencv-python>=4.5.1.48 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (4.12.0.88)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (2.2.6)\n",
      "Requirement already satisfied: six>=1.15.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (1.17.0)\n",
      "Requirement already satisfied: Shapely>=1.7.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (2.1.2)\n",
      "Requirement already satisfied: Pillow in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rapidocr-onnxruntime) (11.3.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (5.29.5)\n",
      "Requirement already satisfied: sympy in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from coloredlogs->onnxruntime>=1.7.0->rapidocr-onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from sympy->onnxruntime>=1.7.0->rapidocr-onnxruntime) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain[google-genai] in /Users/2099070/Library/Python/3.13/lib/python/site-packages (1.0.8)\n",
      "Collecting langchain[google-genai]\n",
      "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=1.1.0 (from langchain[google-genai])\n",
      "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain[google-genai]) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain[google-genai]) (2.11.7)\n",
      "Requirement already satisfied: langchain-google-genai in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain[google-genai]) (3.1.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (0.4.8)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (4.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (1.0.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (0.2.9)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (3.11.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (0.23.0)\n",
      "Requirement already satisfied: anyio in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[google-genai]) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain[google-genai]) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[google-genai]) (1.3.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-google-genai->langchain[google-genai]) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<1.0.0,>=0.9.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from langchain-google-genai->langchain[google-genai]) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (2.28.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (2.40.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (1.74.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (5.29.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/2099070/Library/Python/3.13/lib/python/site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai->langchain[google-genai]) (0.6.1)\n",
      "Downloading langchain-1.1.0-py3-none-any.whl (101 kB)\n",
      "Downloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
      "Installing collected packages: langchain-core, langchain\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 1.0.7\n",
      "\u001b[2K    Uninstalling langchain-core-1.0.7:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-1.0.7\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain 1.0.8 \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-1.0.8:━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-1.0.80m \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain]/2\u001b[0m [langchain]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-1.1.0 langchain-core-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain openai tiktoken rapidocr-onnxruntime\n",
    "\n",
    "!pip install -U \"langchain[google-genai]\"\n",
    "!pip install -qU langchain-community faiss-cpu\n",
    "!pip install -qU  langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b35fb1",
   "metadata": {},
   "source": [
    "FETCHING OPENAI API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18c1f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBCz196fnoMq8IzcJd9MDxF3MphRrIhYLg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key\n",
    "\n",
    "print(gemini_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4dd397",
   "metadata": {},
   "source": [
    "1. DATA INGESTION\n",
    "2. DATA RETRIEVAL\n",
    "3. DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f00f69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/2099070/Library/Python/3.13/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "################DATA INGESTION###############\n",
    "\n",
    "import requests\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814e3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cad4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT A CHAT MODEL\n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# API key is already set from the previous cell that loads .env\n",
    "# os.environ[\"GOOGLE_API_KEY\"] is already configured\n",
    "\n",
    "# model = init_chat_model(\"google_genai:gemini-2.5-pro\")\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efe00108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--11fac380-1d8c-4dd7-b862-0c95543fb3a8-0', usage_metadata={'input_tokens': 21, 'output_tokens': 7, 'total_tokens': 28, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INVOCATION\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4bf52b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore la programmation.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac9c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT AN EMBEDDINGS MODEL\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U \"langchain[google-genai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71832f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT A VECTOR STORE\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748112f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING DOCUMENTS FROM THE WEB\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cde5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLIT DOCUMENTS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STORING DOCUMENTS IN VECTOR STORE\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5332fbd",
   "metadata": {},
   "source": [
    "##---------------------------RETRIEVAL & GENERATION---------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----RAG Agent - DEFINING TOOL----##\n",
    "\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06971095",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----CONSTRUCT THE AGENT----##\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4ef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----TEST IT OUT----##\n",
    "query = (\n",
    "    \"What is the standard method for Task Decomposition?\\n\\n\"\n",
    "    \"Once you get the answer, look up common extensions of that method.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c857e905",
   "metadata": {},
   "source": [
    "##----USING RAG CHAINS - Allow the LLM to use its discretion in generating a tool call to help answer user queries----##\n",
    "\n",
    "✅ Benefits OF RAG CHAIN \n",
    "Search only when needed – The LLM can handle greetings, follow-ups, and simple queries without triggering unnecessary searches.\n",
    "Contextual search queries – By treating search as a tool with a query input, the LLM crafts its own queries that incorporate conversational context.\n",
    "Multiple searches allowed – The LLM can execute several searches in support of a single user query.\n",
    "\n",
    "⚠️ Drawbacks\n",
    "Two inference calls – When a search is performed, it requires one call to generate the query and another to produce the final response.\n",
    "Reduced control – The LLM may skip searches when they are actually needed, or issue extra searches when unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8018e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement this chain by removing tools from the agent and instead incorporating the retrieval step into a custom prompt:\n",
    "\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "@dynamic_prompt\n",
    "def prompt_with_context(request: ModelRequest) -> str:\n",
    "    \"\"\"Inject context into state messages.\"\"\"\n",
    "    last_query = request.state[\"messages\"][-1].text\n",
    "    retrieved_docs = vector_store.similarity_search(last_query)\n",
    "\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpful assistant. Use the following context in your response:\"\n",
    "        f\"\\n\\n{docs_content}\"\n",
    "    )\n",
    "\n",
    "    return system_message\n",
    "\n",
    "\n",
    "agent = create_agent(model, tools=[], middleware=[prompt_with_context])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----TEST IT OUT----##\n",
    "\n",
    "query = \"What is task decomposition?\"\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
